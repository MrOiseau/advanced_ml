# Needed for advanced_ml import
PYTHONPATH=$PYTHONPATH:`pwd`

# Llama cloud, if using Llamaparse
# LLAMA_CLOUD_API_KEY=

OPENAI_API_KEY=

# Models
CHAT_MODEL="gpt-4o-mini"
EMBEDDING_MODEL="text-embedding-3-small"

LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
LANGSMITH_API_KEY=
LANGSMITH_PROJECT="advanced_ml"

PDF_DIR="./data/pdfs"
DB_DIR="./data/db"
DB_COLLECTION="rag_collection_advanced"
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
DATA_DIR="./data"

EVALUATION_DATASET="./data/evaluation/evaluation_dataset_chatgpt_unique.json"
RESULTS_EVALUATION_AVERAGE_METRICS="./data/evaluation/results_evaluation_average_metrics.png"

# Set ADVANCED_CHUNKING=false to use RecursiveCharacterTextSplitter, or ADVANCED_CHUNKING=true for advanced chunking based on semantically similar sentences
ADVANCED_CHUNKING=true

# Set USE_LOCAL_EMBEDDINGS=true to use local HuggingFace embeddings instead of OpenAI API calls (faster for development)
USE_LOCAL_EMBEDDINGS=false

# Set LANGCHAIN_TRACING_V2=false to disable LangSmith warnings if you don't have a LangSmith API key
# LANGCHAIN_TRACING_V2=false

# Minimum number of consecutive words required for highlighting common sequences between databases
MIN_COMMON_WORDS=7